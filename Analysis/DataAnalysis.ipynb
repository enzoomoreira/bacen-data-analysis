{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03410a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. INICIANDO SETUP ---\n",
      "Iniciando o Analisador Bancário...\n",
      "Analisador Bancário iniciado com sucesso!\n",
      "  - 677,413 linhas em COSIF Individual\n",
      "  - 567,956 linhas em COSIF Prudencial\n",
      "  - 8,528,071 linhas em IFDATA Valores\n",
      "  - 190,846 linhas em IFDATA Cadastro\n",
      "  - Mapeamento interno criado para 6,365 nomes únicos.\n",
      "--- SETUP CONCLUÍDO. ANALISADOR PRONTO. ---\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 1: SETUP E INICIALIZAÇÃO DA ANÁLISE\n",
    "# ==============================================================================\n",
    "# Descrição: Importa bibliotecas, configura o ambiente e inicializa o\n",
    "# AnalisadorBancario, que será a ferramenta para todas as coletas de dados.\n",
    "# ------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- 1. INICIANDO SETUP ---\")\n",
    "\n",
    "# Adiciona o diretório 'Code' ao path para encontrar o DataUtils\n",
    "code_dir = Path('..').resolve() / 'Code'\n",
    "if str(code_dir) not in sys.path:\n",
    "    sys.path.append(str(code_dir))\n",
    "\n",
    "from DataUtils import AnalisadorBancario\n",
    "\n",
    "# Configurações de exibição do Pandas\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Inicializa o Analisador (carrega todos os dados em memória)\n",
    "output_dir = Path('..').resolve() / 'Output'\n",
    "analisador = AnalisadorBancario(diretorio_output=str(output_dir))\n",
    "\n",
    "# Garante que a pasta de resultados exista\n",
    "results_dir = Path('.') / 'Results'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"--- SETUP CONCLUÍDO. ANALISADOR PRONTO. ---\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa25bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. CONFIGURANDO PARÂMETROS DA ANÁLISE ---\n",
      "--- CONFIGURAÇÃO CARREGADA. ---\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 2: PAINEL DE CONTROLE DA ANÁLISE\n",
    "# ==============================================================================\n",
    "# Descrição: Este é o único lugar que você precisa alterar para configurar\n",
    "# todo o relatório. Defina aqui os bancos, indicadores e o período desejado.\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- 2. CONFIGURANDO PARÂMETROS DA ANÁLISE ---\")\n",
    "\n",
    "# --- Período da Análise ---\n",
    "DATA_INICIO_SERIES = 202201\n",
    "DATA_FIM_SERIES = 202412\n",
    "DATA_SNAPSHOT = 202412\n",
    "\n",
    "# --- Geração Inteligente de Datas ---\n",
    "data_inicio_dt = pd.to_datetime(f'{DATA_INICIO_SERIES}', format='%Y%m')\n",
    "data_fim_dt = pd.to_datetime(f'{DATA_FIM_SERIES}', format='%Y%m') + pd.tseries.offsets.MonthEnd(0)\n",
    "\n",
    "datas_mensais = pd.date_range(\n",
    "    start=data_inicio_dt,\n",
    "    end=data_fim_dt,\n",
    "    freq='ME'\n",
    ").strftime('%Y%m').astype(int).tolist()\n",
    "\n",
    "datas_trimestrais = pd.date_range(\n",
    "    start=data_inicio_dt,\n",
    "    end=data_fim_dt,\n",
    "    freq='QE'\n",
    ").strftime('%Y%m').astype(int).tolist()\n",
    "\n",
    "# --- Lista de Bancos ---\n",
    "try:\n",
    "    caminho_csv = Path('.') / 'Banks.csv'\n",
    "    df_bancos_interesse = pd.read_csv(caminho_csv, dtype={'CNPJ_8': str}, sep=';')\n",
    "    LISTA_BANCOS = [b for b in df_bancos_interesse['CNPJ_8'].tolist() if b]\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO CRÍTICO: O arquivo '{caminho_csv.name}' não foi encontrado. A análise será interrompida.\")\n",
    "    LISTA_BANCOS = []\n",
    "\n",
    "# --- GRUPO 1: INDICADORES PARA SÉRIES TEMPORAIS (HISTÓRICO COMPLETO) ---\n",
    "INDICADORES_SERIES_TEMPORAIS = {\n",
    "    'Ativo Total': {'fonte': 'IFDATA'},\n",
    "    'RWA': {'fonte': 'IFDATA', 'conta': 'Patrimônio de Referência para Comparação com o RWA'},\n",
    "    'Índice de Basileia': {'fonte': 'IFDATA'},\n",
    "    'Lucro Líquido': {'fonte': 'IFDATA'},\n",
    "    'Patrimônio Líquido': {'fonte': 'IFDATA'},\n",
    "    'Volume de Operações tipo G': {'fonte': 'IFDATA', 'conta': 'G'},\n",
    "    'Volume de Operações tipo H': {'fonte': 'IFDATA', 'conta': 'H'},\n",
    "    'Total de Volume de Operações': {'fonte': 'IFDATA', 'conta': 'Total Geral'}\n",
    "}\n",
    "\n",
    "# --- GRUPO 2: INDICADORES PARA SNAPSHOT (APENAS DATA MAIS RECENTE) ---\n",
    "INDICADORES_SNAPSHOT = {\n",
    "        'Volume de Operações tipo A': {'fonte': 'IFDATA', 'conta': 'A'},\n",
    "        'Volume de Operações tipo AA': {'fonte': 'IFDATA', 'conta': 'AA'},\n",
    "        'Volume de Operações tipo B': {'fonte': 'IFDATA', 'conta': 'B'},\n",
    "        'Volume de Operações tipo C': {'fonte': 'IFDATA', 'conta': 'C'},\n",
    "        'Volume de Operações tipo D': {'fonte': 'IFDATA', 'conta': 'D'},\n",
    "        'Volume de Operações tipo E': {'fonte': 'IFDATA', 'conta': 'E'},\n",
    "        'Volume de Operações tipo F': {'fonte': 'IFDATA', 'conta': 'F'},\n",
    "        'Depósitos a Prazo': {'fonte': 'IFDATA', 'conta': 'Depósitos a Prazo (a4)'},\n",
    "        'Letra de Crédito Imobiliário': {'fonte': 'IFDATA', 'conta': 'Letras de Crédito Imobiliário (c1)'},\n",
    "        'Letra de Crédito Agronegócio': {'fonte': 'IFDATA', 'conta': 'Letras de Crédito do Agronegócio (c2)'},\n",
    "        'Letras Financeiras': {'fonte': 'IFDATA', 'conta': 'Letras Financeiras (c3)'}\n",
    "        }\n",
    "\n",
    "# --- ATRIBUTOS CADASTRAIS (DADOS ESTÁTICOS) ---\n",
    "ATRIBUTOS_CADASTRAIS = ['TCB_IFD_CAD']\n",
    "\n",
    "print(\"--- CONFIGURAÇÃO CARREGADA. ---\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33306edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.1. Otimização: Pré-filtrando DataFrames para máxima performance... ---\n",
      " -> DataFrame IF.DATA pré-filtrado de 8,528,071 para 604,762 linhas.\n",
      "\n",
      "--- 3.2. Coletando todos os componentes necessários... ---\n",
      "\n",
      " -> Coleta concluída. DataFrame original restaurado.\n",
      "\n",
      "--- 3.3. Consolidando e exportando dados para o Power BI... ---\n",
      "\n",
      "============================================================\n",
      ">>> SUCESSO! <<<\n",
      "Relatório de COMPONENTES para o Power BI foi gerado com 4,494 linhas.\n",
      "Arquivo salvo em: 'C:\\Users\\Enzo\\Documents\\Programming\\bacen-data-analysis\\Analysis\\Results\\relatorio_powerbi_202412.xlsx'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 3: COLETA OTIMIZADA E EXPORTAÇÃO DIRETA (VERSÃO FINAL)\n",
    "# ==============================================================================\n",
    "# Descrição: Este pipeline usa a técnica de pré-filtragem para máxima performance\n",
    "# e exporta os componentes brutos diretamente para o Power BI, onde os\n",
    "# cálculos de NPL e ROE serão feitos como Medidas DAX.\n",
    "# ------------------------------------------------------------------------------\n",
    "if LISTA_BANCOS:\n",
    "    # --- ETAPA 1: Pré-filtragem para Performance (\"Bulk Filtering\") ---\n",
    "    print(\"--- 3.1. Otimização: Pré-filtrando DataFrames para máxima performance... ---\")\n",
    "    \n",
    "    todos_indicadores = {**INDICADORES_SERIES_TEMPORAIS, **INDICADORES_SNAPSHOT}\n",
    "    contas_para_buscar = [info.get('conta', nome) for nome, info in todos_indicadores.items()]\n",
    "\n",
    "    # Filtra os DataFrames base UMA ÚNICA VEZ\n",
    "    # Inclui busca por nome e por código para máxima compatibilidade\n",
    "    df_ifdata_trabalho = analisador.df_ifd_val[\n",
    "        (analisador.df_ifd_val['NOME_CONTA_IFD_VAL'].isin(contas_para_buscar)) | \n",
    "        (analisador.df_ifd_val['CONTA_IFD_VAL'].astype(str).isin(contas_para_buscar))\n",
    "    ].copy()\n",
    "\n",
    "    # Guarda os DataFrames originais para restaurar depois\n",
    "    original_ifd_val = analisador.df_ifd_val\n",
    "    \n",
    "    # \"Injeta\" o DataFrame otimizado no analisador para esta sessão\n",
    "    analisador.df_ifd_val = df_ifdata_trabalho\n",
    "    print(f\" -> DataFrame IF.DATA pré-filtrado de {len(original_ifd_val):,} para {len(df_ifdata_trabalho):,} linhas.\")\n",
    "    \n",
    "    # --- ETAPA 2: Coleta de Dados (agora usando os DFs otimizados) ---\n",
    "    dfs_coletados = []\n",
    "    print(\"\\n--- 3.2. Coletando todos os componentes necessários... ---\")\n",
    "    \n",
    "    for banco in LISTA_BANCOS:\n",
    "        for nome_indicador, info in todos_indicadores.items():\n",
    "            # Define a lista de datas correta para cada indicador\n",
    "            if nome_indicador in INDICADORES_SERIES_TEMPORAIS:\n",
    "                datas_para_buscar = datas_trimestrais if info['fonte'].upper() == 'IFDATA' else datas_mensais\n",
    "            else:\n",
    "                datas_para_buscar = [DATA_SNAPSHOT]\n",
    "            \n",
    "            conta_busca = info.get('conta', nome_indicador)\n",
    "            \n",
    "            df_serie = analisador.get_serie_temporal_indicador(\n",
    "                identificador=banco, conta=conta_busca,\n",
    "                datas=datas_para_buscar, fonte=info['fonte'], documento_cosif=info.get('documento'),\n",
    "                fillna=0\n",
    "            )\n",
    "            if not df_serie.empty:\n",
    "                dfs_coletados.append(df_serie)\n",
    "\n",
    "    # Restaura o DataFrame original no analisador para não afetar outras células\n",
    "    analisador.df_ifd_val = original_ifd_val\n",
    "    print(\"\\n -> Coleta concluída. DataFrame original restaurado.\")\n",
    "\n",
    "    if not dfs_coletados:\n",
    "        print(\"\\nNenhum dado foi encontrado para os parâmetros definidos.\")\n",
    "    else:\n",
    "        # --- ETAPA 3: Consolidação e Exportação Final ---\n",
    "        print(\"\\n--- 3.3. Consolidando e exportando dados para o Power BI... ---\")\n",
    "        df_long_base = pd.concat(dfs_coletados, ignore_index=True)\n",
    "        \n",
    "        # Traduz os nomes técnicos para os nomes amigáveis\n",
    "        mapa_nomes = {info.get('conta', nome): nome for nome, info in todos_indicadores.items()}\n",
    "        df_long_base['Indicador'] = df_long_base['Conta'].replace(mapa_nomes)\n",
    "        \n",
    "        # Junção dos atributos cadastrais\n",
    "        df_atributos = analisador.get_atributos_cadastro(identificador=LISTA_BANCOS, atributos=ATRIBUTOS_CADASTRAIS)\n",
    "        df_para_bi = pd.merge(df_long_base, df_atributos, on=['CNPJ_8', 'Nome_Entidade'], how='left')\n",
    "\n",
    "        # Seleciona e reordena as colunas finais\n",
    "        colunas_finais = ['DATA', 'Nome_Entidade', 'CNPJ_8', 'Indicador', 'Valor'] + [col for col in ATRIBUTOS_CADASTRAIS if col in df_para_bi.columns]\n",
    "        df_para_bi = df_para_bi[colunas_finais]\n",
    "\n",
    "        nome_arquivo_saida = f'relatorio_powerbi_202412.xlsx'\n",
    "        caminho_saida = results_dir / nome_arquivo_saida\n",
    "        df_para_bi.to_excel(caminho_saida, index=False, engine='openpyxl')\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\">>> SUCESSO! <<<\")\n",
    "        print(f\"Relatório de COMPONENTES para o Power BI foi gerado com {len(df_para_bi):,} linhas.\")\n",
    "        print(f\"Arquivo salvo em: '{caminho_saida.resolve()}'\")\n",
    "        print(\"=\"*60)\n",
    "else:\n",
    "    print(\"A lista de bancos está vazia. Nenhuma análise foi executada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
